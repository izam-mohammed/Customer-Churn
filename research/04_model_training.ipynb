{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/izam/coding/Customer-Churn'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainerConfig:\n",
    "    root_dir: Path\n",
    "    train_data_path: Path\n",
    "    test_data_path: Path\n",
    "    model_name: str\n",
    "    params: dict\n",
    "    target_col: str\n",
    "    permanent_path: str\n",
    "    auto_select: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CustomerChurn.constants import *\n",
    "from CustomerChurn.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        schema_filepath = SCHEMA_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    \n",
    "    def get_model_trainer_config(self) -> ModelTrainerConfig:\n",
    "        config = self.config.model_trainer\n",
    "        target_col = self.schema.TARGET_COLUMN\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        model_trainer_config = ModelTrainerConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            train_data_path = config.train_data_path,\n",
    "            test_data_path = config.test_data_path,\n",
    "            model_name = config.model_name,\n",
    "            params = self.params,\n",
    "            target_col=target_col.name,\n",
    "            permanent_path=config.permanent_path,\n",
    "            auto_select=config.auto_select,\n",
    "        )\n",
    "\n",
    "        return model_trainer_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from box import ConfigBox\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from CustomerChurn import logger\n",
    "from CustomerChurn.utils.common import save_bin, save_bin_dup\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from scipy.stats import reciprocal, uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(self, config: ModelTrainerConfig):\n",
    "        self.config = config\n",
    "        train = pd.read_csv(self.config.train_data_path)\n",
    "        test = pd.read_csv(self.config.test_data_path)\n",
    "\n",
    "        self.X_train= train.drop([self.config.target_col], axis=1)\n",
    "        self.y_train = train[self.config.target_col]\n",
    "        self.X_test = test.drop([self.config.target_col], axis=1)\n",
    "        self.y_test = test[self.config.target_col]   \n",
    "\n",
    "\n",
    "    def _randomized_search(self, name,clf,params, runs=50): \n",
    "        rand_clf = RandomizedSearchCV(clf, params, n_iter=runs, cv=5, n_jobs=4, random_state=2, verbose=0)     \n",
    "\n",
    "        rand_clf.fit(self.X_train, self.y_train) \n",
    "        best_model = rand_clf.best_estimator_\n",
    "        \n",
    "        # Extract best score\n",
    "        best_score = rand_clf.best_score_\n",
    "\n",
    "        # Print best score\n",
    "        logger.info(\"Trained with {} with score: {:.3f}\".format(name, best_score))\n",
    "\n",
    "        # Predict test set labels\n",
    "        y_pred = best_model.predict(self.X_test)\n",
    "\n",
    "        # Compute accuracy\n",
    "        accuracy = accuracy_score(self.y_test, y_pred)\n",
    "\n",
    "        # Print accuracy\n",
    "        logger.info('Predicted with {} ; Test score : {:.3f}'.format(name, accuracy))\n",
    "        \n",
    "        return best_model, accuracy\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        model_params = self.config.params\n",
    "\n",
    "        models = ConfigBox({\n",
    "            \"Decision_Tree\": {\n",
    "                \"model\" : DecisionTreeClassifier(),\n",
    "                \"params\" : model_params.Decision_Tree,\n",
    "                \"auto\":{\n",
    "                        \"criterion\" : ['gini', 'entropy'],\n",
    "                        \"splitter\" : ['best', 'random'],\n",
    "                        \"max_depth\" : range( 1, 32),\n",
    "                        \"min_samples_split\" : uniform( 0.1, 1.0),\n",
    "                        \"min_samples_leaf\" : uniform( 0.1, 0.5),\n",
    "                        \"max_features\" : ['auto', 'sqrt', 'log2', None],\n",
    "                }\n",
    "            },\n",
    "            \"Random_Forest\": {\n",
    "                \"model\" : RandomForestClassifier(),\n",
    "                \"params\" : model_params.Random_Forest\n",
    "                \"auto\":{\n",
    "                    'n_estimators': range(10, 200),\n",
    "                    'criterion': ['gini', 'entropy'],\n",
    "                    'max_depth': range(1, 20),\n",
    "                    'min_samples_split': range(2, 20),\n",
    "                    'min_samples_leaf': range(1, 20),\n",
    "                    'max_features': ['auto', 'sqrt', 'log2', None],\n",
    "                    'bootstrap': [True, False]\n",
    "                }\n",
    "            },\n",
    "            \"SVC\": {\n",
    "                \"model\" : SVC(),\n",
    "                \"params\" : model_params.SVC,\n",
    "                \"auto\":{\n",
    "                    'C': reciprocal(0.1, 10),  \n",
    "                    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "                    'degree': range(2, 7),\n",
    "                    'gamma': ['scale', 'auto'] + list(uniform(0.1, 1.0).rvs(10)),\n",
    "                    'coef0': uniform(-1, 1)\n",
    "                }\n",
    "            },\n",
    "            \"LogisticRegression\":{\n",
    "                \"model\" : LogisticRegression(),\n",
    "                \"params\" : model_params.LogisticRegression,\n",
    "                \"auto\" : {\n",
    "                        'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "                        'C': uniform(0.1, 10), \n",
    "                        'fit_intercept': [True, False],\n",
    "                        'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "                        'max_iter': range(50, 500, 50)\n",
    "                }\n",
    "            },\n",
    "            \"MultinomialNB\":{\n",
    "                \"model\" : MultinomialNB(),\n",
    "                \"params\" : model_params.MultinomialNB,\n",
    "                \"auto\": {\n",
    "                        'alpha': uniform(0.1, 2.0), \n",
    "                        'fit_prior': [True, False],\n",
    "                        'class_prior': [None, list(uniform(0.1, 1.0).rvs(3))] \n",
    "                    }\n",
    "            },\n",
    "            \"GradientBoost\":{\n",
    "                \"model\": GradientBoostingClassifier(),\n",
    "                \"params\" : model_params.GradientBoost,\n",
    "                \"auto\": {\n",
    "                        'learning_rate': uniform(0.01, 0.2),  # Uniform distribution for learning_rate\n",
    "                        'n_estimators': range(50, 200, 30),\n",
    "                        'max_depth': range(3, 10),\n",
    "                        'min_samples_split': uniform(0.1, 1.0),  # Uniform distribution for min_samples_split\n",
    "                        'min_samples_leaf': uniform(0.1, 0.5),   # Uniform distribution for min_samples_leaf\n",
    "                        'subsample': uniform(0.5, 1.0),           # Uniform distribution for subsample\n",
    "                        'max_features': ['auto', 'sqrt', 'log2', None],\n",
    "                }\n",
    "            },\n",
    "            \"AdaBoost\":{\n",
    "                \"model\" : AdaBoostClassifier(),\n",
    "                \"params\" : model_params.AdaBoost,\n",
    "                \"auto\":{\n",
    "                        'n_estimators': range(50, 200),\n",
    "                        'learning_rate': uniform(0.01, 1.0),  # Uniform distribution for learning_rate\n",
    "                        'algorithm': ['SAMME', 'SAMME.R'],\n",
    "                        'base_estimator': [None, DecisionTreeClassifier(max_depth=1), DecisionTreeClassifier(max_depth=2)],\n",
    "                        'loss': ['linear', 'square', 'exponential'],\n",
    "                }\n",
    "            },\n",
    "            \"XGBoost\":{\n",
    "                \"model\" : XGBClassifier(),\n",
    "                \"params\" : model_params.XGBoost,\n",
    "                \"auto\":{\n",
    "                        'learning_rate': uniform(0.01, 0.2),\n",
    "                        'n_estimators': range(50, 200),\n",
    "                        'max_depth': range(3, 10),\n",
    "                        'min_child_weight': range(1, 10),\n",
    "                        'subsample': uniform(0.5, 1.0),\n",
    "                        'colsample_bytree': uniform(0.5, 1.0),\n",
    "                        'gamma': uniform(0, 1),\n",
    "                        'reg_alpha': uniform(0, 1),\n",
    "                        'reg_lambda': uniform(0, 1),\n",
    "                        'scale_pos_weight': range(1, 10),\n",
    "                        'base_score': uniform(0.1, 0.9),\n",
    "                        'booster': ['gbtree', 'gblinear', 'dart'],\n",
    "                        'n_jobs': [-1],\n",
    "                        'random_state': range(1, 100),\n",
    "                }\n",
    "            },\n",
    "        })\n",
    "\n",
    "        create_directories([os.path.join(self.config.root_dir, \"models\")])\n",
    "        trained_models = []\n",
    "        for model in models:\n",
    "            clf = models[model].model\n",
    "            params = models[model].params\n",
    "\n",
    "            if self.config.auto_select:\n",
    "                params = models[model].auto\n",
    "            else:\n",
    "                params = models[model].params\n",
    "            if model==\"XGBoost\":\n",
    "                clf_model, score = self._randomized_search(name=str(model) ,clf=clf, params=params, runs=300)\n",
    "            else:\n",
    "                clf_model, score = self._randomized_search(name=str(model) ,clf=clf, params=params)\n",
    "            trained_models.append((clf_model, score))\n",
    "\n",
    "            save_bin(data=clf_model, path=Path(os.path.join(self.config.root_dir, f\"models/{str(model)}.joblib\")))\n",
    "        \n",
    "        trained_models = sorted(trained_models, key=lambda x:x[1], reverse=True)  # [(model, score), (model, score), ..]\n",
    "        best_model = trained_models[0][0]  # taking the model\n",
    "\n",
    "        save_bin(data=best_model, path=Path(os.path.join(self.config.root_dir, self.config.model_name)))\n",
    "        save_bin_dup(data=best_model, path=Path(os.path.join(self.config.permanent_path, \"model.joblib\")))\n",
    "\n",
    "        best_model_name = str(best_model)[:str(best_model).find(\"(\")]\n",
    "        best_model_score = round(trained_models[0][1], 3)\n",
    "        logger.info(f\"Saved main model as {best_model_name}, with score - {best_model_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-12-16 10:30:15,737: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2023-12-16 10:30:15,741: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2023-12-16 10:30:15,749: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2023-12-16 10:30:15,750: INFO: common: created directory at: artifacts]\n",
      "[2023-12-16 10:30:15,751: INFO: common: created directory at: artifacts/model_trainer]\n",
      "[2023-12-16 10:30:15,769: INFO: common: created directory at: artifacts/model_trainer/models]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/izam/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 4 is smaller than n_iter=50. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-12-16 10:30:17,814: INFO: 2321620229: Trained with Decision_Tree with score: 0.726]\n",
      "[2023-12-16 10:30:17,817: INFO: 2321620229: Predicted with Decision_Tree ; Test score : 0.738]\n",
      "[2023-12-16 10:30:17,820: INFO: common: binary file saved at: artifacts/model_trainer/models/Decision_Tree.joblib]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/izam/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 2 is smaller than n_iter=50. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-12-16 10:30:18,961: INFO: 2321620229: Trained with Random_Forest with score: 0.795]\n",
      "[2023-12-16 10:30:18,983: INFO: 2321620229: Predicted with Random_Forest ; Test score : 0.815]\n",
      "[2023-12-16 10:30:19,032: INFO: common: binary file saved at: artifacts/model_trainer/models/Random_Forest.joblib]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/izam/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 4 is smaller than n_iter=50. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-12-16 10:30:21,945: INFO: 2321620229: Trained with SVC with score: 0.791]\n",
      "[2023-12-16 10:30:22,087: INFO: 2321620229: Predicted with SVC ; Test score : 0.803]\n",
      "[2023-12-16 10:30:22,090: INFO: common: binary file saved at: artifacts/model_trainer/models/SVC.joblib]\n",
      "[2023-12-16 10:30:22,195: INFO: 2321620229: Trained with LogisticRegression with score: 0.799]\n",
      "[2023-12-16 10:30:22,198: INFO: 2321620229: Predicted with LogisticRegression ; Test score : 0.808]\n",
      "[2023-12-16 10:30:22,200: INFO: common: binary file saved at: artifacts/model_trainer/models/LogisticRegression.joblib]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/izam/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 3 is smaller than n_iter=50. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/home/izam/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 2 is smaller than n_iter=50. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-12-16 10:30:22,304: INFO: 2321620229: Trained with MultinomialNB with score: 0.779]\n",
      "[2023-12-16 10:30:22,307: INFO: 2321620229: Predicted with MultinomialNB ; Test score : 0.797]\n",
      "[2023-12-16 10:30:22,308: INFO: common: binary file saved at: artifacts/model_trainer/models/MultinomialNB.joblib]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/izam/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 3 is smaller than n_iter=50. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-12-16 10:30:29,012: INFO: 2321620229: Trained with GradientBoost with score: 0.797]\n",
      "[2023-12-16 10:30:29,016: INFO: 2321620229: Predicted with GradientBoost ; Test score : 0.808]\n",
      "[2023-12-16 10:30:29,020: INFO: common: binary file saved at: artifacts/model_trainer/models/GradientBoost.joblib]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/izam/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 4 is smaller than n_iter=50. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-12-16 10:30:32,354: INFO: 2321620229: Trained with AdaBoost with score: 0.799]\n",
      "[2023-12-16 10:30:32,406: INFO: 2321620229: Predicted with AdaBoost ; Test score : 0.814]\n",
      "[2023-12-16 10:30:32,462: INFO: common: binary file saved at: artifacts/model_trainer/models/AdaBoost.joblib]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/izam/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 4 is smaller than n_iter=50. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-12-16 10:30:32,980: INFO: 2321620229: Trained with XGBoost with score: 0.799]\n",
      "[2023-12-16 10:30:32,985: INFO: 2321620229: Predicted with XGBoost ; Test score : 0.820]\n",
      "[2023-12-16 10:30:32,988: INFO: common: binary file saved at: artifacts/model_trainer/models/XGBoost.joblib]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/izam/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 4 is smaller than n_iter=50. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/home/izam/miniconda3/envs/customerchurn/lib/python3.10/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n",
      "  warnings.warn(\n",
      "/home/izam/miniconda3/envs/customerchurn/lib/python3.10/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n",
      "  warnings.warn(\n",
      "/home/izam/miniconda3/envs/customerchurn/lib/python3.10/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n",
      "  warnings.warn(\n",
      "/home/izam/miniconda3/envs/customerchurn/lib/python3.10/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n",
      "  warnings.warn(\n",
      "/home/izam/miniconda3/envs/customerchurn/lib/python3.10/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n",
      "  warnings.warn(\n",
      "/home/izam/miniconda3/envs/customerchurn/lib/python3.10/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n",
      "  warnings.warn(\n",
      "/home/izam/miniconda3/envs/customerchurn/lib/python3.10/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n",
      "  warnings.warn(\n",
      "/home/izam/miniconda3/envs/customerchurn/lib/python3.10/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n",
      "  warnings.warn(\n",
      "/home/izam/miniconda3/envs/customerchurn/lib/python3.10/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n",
      "  warnings.warn(\n",
      "/home/izam/miniconda3/envs/customerchurn/lib/python3.10/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n",
      "  warnings.warn(\n",
      "/home/izam/miniconda3/envs/customerchurn/lib/python3.10/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n",
      "  warnings.warn(\n",
      "/home/izam/miniconda3/envs/customerchurn/lib/python3.10/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-12-16 10:30:33,983: INFO: 2321620229: Trained with LGBM with score: 0.799]\n",
      "[2023-12-16 10:30:33,987: INFO: 2321620229: Predicted with LGBM ; Test score : 0.807]\n",
      "[2023-12-16 10:30:33,992: INFO: common: binary file saved at: artifacts/model_trainer/models/LGBM.joblib]\n",
      "[2023-12-16 10:30:34,001: INFO: common: binary file saved at: artifacts/model_trainer/model.joblib]\n",
      "[2023-12-16 10:30:34,008: INFO: common: binary file saved at: saved_models/model_01.joblib]\n",
      "[2023-12-16 10:30:34,011: INFO: 2321620229: Saved main model as XGBClassifier, with score - 0.82]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_trainer_config = config.get_model_trainer_config()\n",
    "    model_trainer_config = ModelTrainer(config=model_trainer_config)\n",
    "    model_trainer_config.train()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "customerchurn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
